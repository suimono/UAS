{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Konfigurasi path\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "OUTPUT_FILE = Path(\"data/processed/cases.json\")\n",
    "LOG_FILE = Path(\"data/logs/extraction.log\")\n",
    "\n",
    "def setup_logging():\n",
    "    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(LOG_FILE, encoding='utf-8', mode='a'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "class EnhancedPatternExtractor:\n",
    "    \"\"\"Mengelola koleksi pola regex yang digunakan untuk ekstraksi data.\"\"\"\n",
    "    def __init__(self):\n",
    "        # Pattern untuk nomor perkara (Tidak Berubah)\n",
    "        self.NOMOR_PERKARA_PATTERNS = [\n",
    "            re.compile(r\"PUTUSAN\\s+Nomor\\s*[:\\-]?\\s*(\\d{1,5}\\/[\\w\\.\\-]+?\\/\\d{4}\\/[\\w\\.]+)\", re.IGNORECASE),\n",
    "            re.compile(r\"Nomor\\s*[:\\-]?\\s*(\\d{1,5}\\/[\\w\\.\\-]+?\\/\\d{4}\\/[\\w\\.]+)\", re.IGNORECASE),\n",
    "            re.compile(r\"No\\.\\s*(\\d{1,5}\\/[\\w\\.\\-]+?\\/\\d{4})\", re.IGNORECASE),\n",
    "            re.compile(r\"(\\d{1,5}\\/[\\w\\.\\-]+?\\/\\d{4}(?:\\/[\\w\\.]+)?)\\s*\\n\", re.IGNORECASE),\n",
    "            re.compile(r\"(\\d{1,5}\\s*[PKK]{1,2}\\/[\\w\\.\\-]+?\\/\\d{4})\", re.IGNORECASE)\n",
    "        ]\n",
    "        \n",
    "        # Pattern untuk tanggal (Tidak Berubah)\n",
    "        self.DATE_PATTERNS = [\n",
    "            re.compile(r\"(\\d{1,2})\\s+(Januari|Februari|Maret|April|Mei|Juni|Juli|Agustus|September|Oktober|November|Desember)\\s+(\\d{4})\", re.IGNORECASE),\n",
    "            re.compile(r\"(\\d{1,2})[\\/\\-](\\d{1,2})[\\/\\-](\\d{4})\"),\n",
    "            re.compile(r\"(\\d{4})[\\/\\-](\\d{1,2})[\\/\\-](\\d{1,2})\"),\n",
    "            re.compile(r\"tanggal\\s+(\\d{1,2})\\s+(\\w+)\\s+(\\d{4})\", re.IGNORECASE),\n",
    "            re.compile(r\"pada\\s+hari\\s+\\w+\\s+tanggal\\s+(\\d{1,2})\\s+(\\w+)\\s+(\\d{4})\", re.IGNORECASE)\n",
    "        ]\n",
    "        \n",
    "        # Pattern untuk jenis perkara (Tidak Berubah)\n",
    "        self.JENIS_PERKARA_PATTERNS = [\n",
    "            re.compile(r\"Tindak\\s+Pidana\\s+Korupsi\", re.IGNORECASE),\n",
    "            re.compile(r\"Tipikor\", re.IGNORECASE),\n",
    "            re.compile(r\"Narkotika\", re.IGNORECASE),\n",
    "            re.compile(r\"Pidana\\s+Khusus\", re.IGNORECASE),\n",
    "            re.compile(r\"Pidana\\s+Umum\", re.IGNORECASE),\n",
    "            re.compile(r\"Perdata\", re.IGNORECASE),\n",
    "            re.compile(r\"Tata\\s+Usaha\\s+Negara\", re.IGNORECASE),\n",
    "            re.compile(r\"TUN\", re.IGNORECASE),\n",
    "            re.compile(r\"PHI\", re.IGNORECASE),\n",
    "            re.compile(r\"Perkawinan\", re.IGNORECASE),\n",
    "            re.compile(r\"Waris\", re.IGNORECASE),\n",
    "            re.compile(r\"Ekonomi\\s+Syariah\", re.IGNORECASE),\n",
    "            re.compile(r\"Gugatan\\s+Sederhana\", re.IGNORECASE),\n",
    "            re.compile(r\"Lalu\\s+Lintas\", re.IGNORECASE),\n",
    "            re.compile(r\"Ketenagakerjaan\", re.IGNORECASE)\n",
    "        ]\n",
    "        \n",
    "        # Pattern untuk pasal (Tidak Berubah)\n",
    "        self.PASAL_PATTERNS = [\n",
    "            re.compile(\n",
    "                r\"(?:terbukti|bersalah|melakukan\\s+tindak\\s+pidana|dihukum)\\s+.*?\"\n",
    "                r\"(?:sebagaimana\\s+diatur\\s+dalam|melanggar|berdasarkan)\\s+\"\n",
    "                r\"((?:Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)\"\n",
    "                r\"(?:[\\s\\.\\,\\;]*(?:jo\\.?|juncto|dan|atau|serta)?\\s*Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)*)\"\n",
    "                r\"(?:\\s+Undang-Undang\\s+Nomor\\s+\\d+)?\",\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            ),\n",
    "            re.compile(\n",
    "                r\"(?:menyatakan|memutuskan|menimbang|mengadili|berdasarkan)\\s+.*?\"\n",
    "                r\"((?:Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)\"\n",
    "                r\"(?:[\\s\\.\\,\\;]*(?:jo\\.?|juncto|dan|atau|serta)?\\s*Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)*)\"\n",
    "                r\"(?:\\s+Undang-Undang\\s+Nomor\\s+\\d+)?\",\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            ),\n",
    "            re.compile(r\"((?:Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)(?:[\\s\\.\\,\\;]*(?:jo\\.?|juncto|dan|atau|serta)?\\s*Pasal\\s+\\d+(?:\\s+Ayat\\s*\\(\\d+\\))?(?:\\s+huruf\\s+[a-zA-Z])?)*)\", re.IGNORECASE)\n",
    "        ]\n",
    "        \n",
    "        # --- PERBAIKAN DI SINI: Pattern untuk data personal (nama) ---\n",
    "        # Pola disempurnakan untuk lebih akurat menangkap nama dan memfilter noise\n",
    "        self.PERSONAL_PATTERNS = {\n",
    "            'nama': [\n",
    "                # Pola terkuat: Nama yang diikuti oleh info identitas (TTL, Umur, JK, Pekerjaan, Alamat)\n",
    "                # Menangkap nama, opsional gelar/peran di depannya, lalu nama utama, opsional bin/binti.\n",
    "                re.compile(r\"(?:Terdakwa|Penggugat|Tergugat|Pemohon|Pembanding|Terbanding|Kuasa Hukum|Jaksa Penuntut Umum|Penasehat Hukum|Saksi|Ahli)?\\s*[:\\-\\,\\.\\(\\)\\s]*([A-Za-z][a-zA-Z\\s\\.\\-']{2,80}(?:\\s+(?:bin|binti)\\s+[A-Za-z][a-zA-Z\\s\\.\\-']{2,80})?)(?:\\s*,)?\\s*(?:Tempat\\s+lahir|TTL|lahir|Umur|Usia|Jenis\\s+Kelamin|Pekerjaan|Alamat|Pekerjaan|Jabatan)\", re.IGNORECASE),\n",
    "                # Nama Lengkap: [Nama] atau Nama : [Nama]\n",
    "                re.compile(r\"(?:Nama|Nama Lengkap)\\s*[:\\-]?\\s*([A-Za-z][a-zA-Z\\s\\.\\-']{2,80}(?:\\s+(?:bin|binti)\\s+[A-Za-z][a-zA-Z\\s\\.\\-']{2,80})?)\", re.IGNORECASE),\n",
    "                # Peran: [Terdakwa/Penggugat/dll.]: [Nama]\n",
    "                re.compile(r\"(?:Terdakwa|Penggugat|Tergugat|Pemohon|Pembanding|Terbanding|Pemohon Kasasi|Termohon Kasasi|Jaksa Penuntut Umum)\\s*[:\\-]?\\s*([A-Za-z][a-zA-Z\\s\\.\\-']{2,80}(?:\\s+(?:bin|binti)\\s+[A-Za-z][a-zA-Z\\s\\.\\-']{2,80})?)\", re.IGNORECASE),\n",
    "                # a.n. [Nama] atau oleh: [Nama]\n",
    "                re.compile(r\"(?:a\\.n\\.|oleh)\\s*:\\s*([A-Za-z][a-zA-Z\\s\\.\\-']{2,80}(?:\\s+(?:bin|binti)\\s+[A-Za-z][a-zA-Z\\s\\.\\-']{2,80})?)\", re.IGNORECASE),\n",
    "                # Menyatakan/Menjatuhkan pidana kepada Terdakwa [Nama]\n",
    "                re.compile(r\"(?:menyatakan|menjatuhkan)\\s+(?:pidana|hukuman)\\s+kepada\\s+(?:Terdakwa|Para Terdakwa|Anak)\\s+([A-Za-z][a-zA-Z\\s\\.\\-']{2,80}(?:\\s+(?:bin|binti)\\s+[A-Za-z][a-zA-Z\\s\\.\\-']{2,80})?)\", re.IGNORECASE)\n",
    "            ],\n",
    "            'umur': [\n",
    "                re.compile(r\"Umur[\\/\\s]*Tanggal\\s*lahir\\s*[:\\-]?\\s*(\\d{1,3})\\s*(?:tahun|thn)\", re.IGNORECASE),\n",
    "                re.compile(r\"Umur\\s*[:\\-]?\\s*(\\d{1,3})\\s*(?:tahun|thn)\", re.IGNORECASE)\n",
    "            ],\n",
    "            'jenis_kelamin': [\n",
    "                re.compile(r\"Jenis\\s+Kelamin\\s*[:\\-]?\\s*(Laki-laki|Perempuan|L|P)\\b\", re.IGNORECASE),\n",
    "                re.compile(r\"Kelamin\\s*[:\\-]?\\s*(Laki-laki|Perempuan|L|P)\\b\", re.IGNORECASE)\n",
    "            ],\n",
    "            'pekerjaan': [\n",
    "                re.compile(r\"Pekerjaan\\s*[:\\-]?\\s*([^:\\n]{3,60})\", re.IGNORECASE),\n",
    "                re.compile(r\"Jabatan\\s*[:\\-]?\\s*([^:\\n]{3,60})\", re.IGNORECASE)\n",
    "            ],\n",
    "            'alamat': [\n",
    "                re.compile(r\"(?:Tempat\\s+Tinggal|Alamat)\\s*[:\\-]?\\s*([^:\\n]{10,250}\\.?\\s*(?:RT|RW|No|Jalan|Kelurahan|Kecamatan|Kota|Kabupaten|Provinsi)\\s*[^:\\n]{5,100})?\", re.IGNORECASE),\n",
    "                re.compile(r\"beralamat\\s+di\\s+([^:\\n]{10,250}\\.?\\s*(?:RT|RW|No|Jalan|Kelurahan|Kecamatan|Kota|Kabupaten|Provinsi)\\s*[^:\\n]{5,100})?\", re.IGNORECASE)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        self.STATUS_HUKUMAN_PATTERNS = [\n",
    "            re.compile(r'(?:menyatakan|mengadili).*?(?:terbukti|bersalah|tidak\\s+terbukti|bebas|dihukum|dipidana).*?dengan\\s+pidana\\s+([^.\\n]{20,300}\\.?)(?:\\n|$)', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'(?:menyatakan|memutuskan|mengadili).*?(?:terbukti\\s+secara\\s+sah\\s+dan\\s+meyakinkan|bersalah|tidak\\s+terbukti|bebas)[^\\.]*\\.?', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'(?:pidana|hukuman).*?(?:penjara|denda|kurungan|rehabilitasi|bebas).*?[^\\.]*\\.?', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'(?:terdakwa|pemohon).*?(?:dipidana|dijatuhi|dihukum).*?[^\\.]*\\.?', re.IGNORECASE | re.DOTALL)\n",
    "        ]\n",
    "\n",
    "class ImprovedSmartExtractor:\n",
    "    \"\"\"\n",
    "    Kelas untuk mengekstrak metadata terstruktur dari teks dokumen hukum mentah.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.patterns = EnhancedPatternExtractor()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self.BULAN_MAP = {\n",
    "            'januari': '01', 'februari': '02', 'maret': '03', 'april': '04',\n",
    "            'mei': '05', 'juni': '06', 'juli': '07', 'agustus': '08',\n",
    "            'september': '09', 'oktober': '10', 'november': '11', 'desember': '12'\n",
    "        }\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Bersihkan teks dari karakter tidak perlu (Tidak Berubah).\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        text = text.replace('\\x00', ' ').replace('\\xa0', ' ')\n",
    "        text = re.sub(r'[\\r\\n]+', '\\n', text)\n",
    "        text = re.sub(r'[ \\t]+', ' ', text)\n",
    "        text = re.sub(r'\\s*\\(\\s*', '(', text)\n",
    "        text = re.sub(r'\\s*\\)\\s*', ')', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def _find_first_valid_match(self, text: str, patterns: List[re.Pattern], search_limit: int) -> str:\n",
    "        \"\"\"Mencari dan mengembalikan match pertama yang valid (Tidak Berubah).\"\"\"\n",
    "        search_area = text[:search_limit]\n",
    "        for pattern in patterns:\n",
    "            match = pattern.search(search_area)\n",
    "            if match:\n",
    "                result = match.group(1).strip() if len(match.groups()) > 0 else match.group(0).strip()\n",
    "                result = re.sub(r'\\s+', ' ', result).strip()\n",
    "                if result:\n",
    "                    return result\n",
    "        return \"\"\n",
    "\n",
    "    def extract_nomor_perkara(self, text: str) -> str:\n",
    "        \"\"\"Ekstrak nomor perkara (Tidak Berubah).\"\"\"\n",
    "        nomor = self._find_first_valid_match(text, self.patterns.NOMOR_PERKARA_PATTERNS, 5000)\n",
    "        nomor = nomor.replace(\"Nomor :\", \"\").replace(\"No.\", \"\").strip()\n",
    "        return nomor\n",
    "\n",
    "    def extract_tanggal(self, text: str) -> str:\n",
    "        \"\"\"Ekstrak tanggal (Tidak Berubah).\"\"\"\n",
    "        search_area = text[:8000] \n",
    "        \n",
    "        for pattern in self.patterns.DATE_PATTERNS:\n",
    "            matches = pattern.finditer(search_area)\n",
    "            for match in matches:\n",
    "                start_pos = max(0, match.start() - 150)\n",
    "                end_pos = min(len(search_area), match.end() + 150)\n",
    "                context = search_area[start_pos:end_pos].lower()\n",
    "                \n",
    "                if any(keyword in context for keyword in ['lahir', 'usia', 'umur', 'ktp', 'identitas', 'akta', 'ijazah']):\n",
    "                    self.logger.debug(f\"Skipping date '{match.group(0)}' due to context: {context[:50]}...\")\n",
    "                    continue\n",
    "                \n",
    "                day, month, year = None, None, None\n",
    "                if len(match.groups()) == 3:\n",
    "                    day, month, year = match.groups()\n",
    "                elif len(match.groups()) == 4:\n",
    "                    day, month, year = match.group(1), match.group(2), match.group(3)\n",
    "                \n",
    "                if day and month and year:\n",
    "                    if month.lower() in self.BULAN_MAP:\n",
    "                        month_str = self.BULAN_MAP[month.lower()]\n",
    "                    elif month.isdigit() and 1 <= int(month) <= 12:\n",
    "                        month_str = f\"{int(month):02d}\"\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        day_num = int(day)\n",
    "                        year_num = int(year)\n",
    "                        month_num = int(month_str)\n",
    "                        \n",
    "                        if 1 <= day_num <= 31 and 1 <= month_num <= 12 and 1990 <= year_num <= datetime.now().year + 5:\n",
    "                            return f\"{year_num}-{month_str}-{int(day_num):02d}\"\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        return \"\"\n",
    "\n",
    "    def extract_jenis_perkara(self, text: str) -> str:\n",
    "        \"\"\"Ekstrak jenis perkara (Tidak Berubah).\"\"\"\n",
    "        jenis = self._find_first_valid_match(text, self.patterns.JENIS_PERKARA_PATTERNS, 5000)\n",
    "        if jenis:\n",
    "            return jenis.title()\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        if re.search(r'tindak\\s+pidana\\s+korupsi|korupsi|suap|gratifikasi|tipikor', text_lower):\n",
    "            return \"Tindak Pidana Korupsi\"\n",
    "        elif re.search(r'narkoba|narkotika|psikotropika', text_lower):\n",
    "            return \"Narkotika\"\n",
    "        elif re.search(r'pidana\\s+khusus|pid.sus', text_lower):\n",
    "            return \"Pidana Khusus\"\n",
    "        elif re.search(r'pidana\\s+umum|pid.umum', text_lower):\n",
    "            return \"Pidana Umum\"\n",
    "        elif re.search(r'perdata|pdt', text_lower):\n",
    "            return \"Perdata\"\n",
    "        elif re.search(r'tata\\s+usaha\\s+negara|tun', text_lower):\n",
    "            return \"Tata Usaha Negara\"\n",
    "        \n",
    "        return \"\"\n",
    "\n",
    "    def extract_pasal(self, text: str) -> List[str]:\n",
    "        \"\"\"Ekstrak pasal-pasal yang dilanggar (Tidak Berubah, sudah diperbaiki di iterasi sebelumnya).\"\"\"\n",
    "        pasal_found = set()\n",
    "        \n",
    "        for pattern in self.patterns.PASAL_PATTERNS:\n",
    "            matches = pattern.finditer(text)\n",
    "            for match in matches:\n",
    "                pasal_text = match.group(1).strip() if len(match.groups()) > 0 else match.group(0).strip()\n",
    "                \n",
    "                pasal_text = re.sub(r'\\s+', ' ', pasal_text)\n",
    "                pasal_text = re.sub(r'Ayat\\s*\\(\\s*(\\d+)\\s*\\)', r'Ayat (\\1)', pasal_text, re.IGNORECASE)\n",
    "                pasal_text = re.sub(r'huruf\\s*([a-zA-Z])', r'huruf \\1', pasal_text, re.IGNORECASE)\n",
    "                pasal_text = pasal_text.replace(\"jo.\", \"jo\").replace(\"juncto\", \"jo\").replace(\"serta\", \"dan\").replace(\"atau\", \"dan\")\n",
    "\n",
    "                sub_pasals = re.split(r'\\s+(?:jo|dan)\\s+', pasal_text, flags=re.IGNORECASE)\n",
    "                \n",
    "                for p in sub_pasals:\n",
    "                    p = p.strip()\n",
    "                    if re.search(r'Pasal\\s+\\d+', p, re.IGNORECASE):\n",
    "                        if 5 <= len(p) <= 150:\n",
    "                            pasal_found.add(p.title())\n",
    "\n",
    "        return sorted(list(pasal_found))\n",
    "\n",
    "    # --- PERBAIKAN DI SINI: extract_personal_data (untuk nama) ---\n",
    "    def extract_personal_data(self, text: str, field: str) -> str:\n",
    "        \"\"\"Ekstrak data personal berdasarkan field dengan validasi lebih ketat.\"\"\"\n",
    "        if field not in self.patterns.PERSONAL_PATTERNS:\n",
    "            return \"\"\n",
    "        \n",
    "        search_area = text[:20000] # Perluas area pencarian untuk data personal\n",
    "        \n",
    "        best_match_value = \"\" # Untuk menyimpan kandidat nama terbaik\n",
    "        \n",
    "        for pattern in self.patterns.PERSONAL_PATTERNS[field]:\n",
    "            matches = pattern.findall(search_area)\n",
    "            if matches:\n",
    "                for match in matches:\n",
    "                    # Ambil group pertama jika itu tuple (dari capture group), atau match langsung\n",
    "                    value = match[0].strip() if isinstance(match, tuple) else match.strip()\n",
    "                    \n",
    "                    # Pembersihan umum dari karakter yang tidak diinginkan dalam nama/teks\n",
    "                    value = re.sub(r'[^\\w\\s\\.\\-,\\(\\)/]', '', value).strip()\n",
    "                    value = re.sub(r'\\s+', ' ', value).strip() # Normalisasi spasi\n",
    "\n",
    "                    # Validasi spesifik per bidang\n",
    "                    if field == 'umur':\n",
    "                        if value.isdigit() and 10 <= int(value) <= 100:\n",
    "                            return value\n",
    "                    elif field == 'jenis_kelamin':\n",
    "                        if value.lower() in ['laki-laki', 'perempuan', 'l', 'p']:\n",
    "                            return \"Laki-laki\" if value.lower() in ['laki-laki', 'l'] else \"Perempuan\"\n",
    "                    elif field == 'nama':\n",
    "                        # Kriteria validasi nama\n",
    "                        if len(value) < 3 or not re.search(r'[a-zA-Z]', value): # Harus punya huruf dan cukup panjang\n",
    "                            continue\n",
    "                        \n",
    "                        # Filter nama yang terlalu umum atau bukan nama individu\n",
    "                        excluded_terms = [\"terdakwa\", \"penggugat\", \"tergugat\", \"pemohon\", \"kuasa hukum\", \"majelis hakim\", \n",
    "                                          \"saksi\", \"ahli\", \"jaksa penuntut umum\", \"panitera\", \"hakim ketua\", \n",
    "                                          \"hakim anggota\", \"panitera pengganti\", \"para terdakwa\", \"para penggugat\"]\n",
    "                        if value.lower() in excluded_terms or any(term in value.lower() for term in excluded_terms):\n",
    "                            continue\n",
    "\n",
    "                        # Jika nama mengandung \"bin\" atau \"binti\", itu indikator kuat nama lengkap\n",
    "                        if re.search(r'\\b(bin|binti)\\b', value, re.IGNORECASE) and len(value.split()) >= 3:\n",
    "                            # Prioritas tinggi: jika ini ditemukan, langsung kembalikan\n",
    "                            return value.title() \n",
    "\n",
    "                        # Cek apakah nama terdiri dari 2 kata atau lebih dan setiap kata dimulai kapital\n",
    "                        # Contoh: \"Budi Santoso\", \"Dr. A. Yani\"\n",
    "                        if re.match(r\"^(?:[A-Z][a-zA-Z\\.\\-']+\\s+){1,}[A-Z][a-zA-Z\\.\\-']+$\", value):\n",
    "                            # Jika ini lebih panjang atau lebih spesifik dari kandidat sebelumnya\n",
    "                            if len(value) > len(best_match_value):\n",
    "                                best_match_value = value.title() # Simpan sebagai kandidat terbaik\n",
    "                            \n",
    "                        # Fallback untuk nama satu kata kapital atau dua kata dengan kapital di awal saja\n",
    "                        elif len(value.split()) >= 1 and re.match(r\"^[A-Z][a-zA-Z\\s\\.\\-']+$\", value):\n",
    "                             if len(value) > len(best_match_value): # Simpan jika lebih panjang\n",
    "                                best_match_value = value.title()\n",
    "                        \n",
    "                        # Jika sudah menemukan kandidat yang cukup baik, bisa langsung break\n",
    "                        if best_match_value and len(best_match_value.split()) > 1: # Minimal 2 kata\n",
    "                            break # Hentikan pencarian pola lain untuk nama ini\n",
    "                        \n",
    "                    elif field == 'pekerjaan' and len(value) >= 3 and len(value) <= 60:\n",
    "                        return value\n",
    "                    elif field == 'alamat' and len(value) >= 20 and len(value) <= 250:\n",
    "                        if any(k in value.lower() for k in ['jalan', 'no', 'rt', 'rw', 'kelurahan', 'kecamatan', 'kota', 'kabupaten']):\n",
    "                            return value\n",
    "                \n",
    "        # Jika loop selesai, kembalikan kandidat nama terbaik yang ditemukan\n",
    "        return best_match_value\n",
    "\n",
    "    def extract_status_hukuman(self, text: str) -> str:\n",
    "        \"\"\"Ekstrak status hukuman/putusan (Sudah diperbaiki dari error sebelumnya).\"\"\"\n",
    "        search_area = text[-7000:] if len(text) > 7000 else text\n",
    "        \n",
    "        # Menggunakan pola yang sudah dikompilasi dari EnhancedPatternExtractor\n",
    "        for pattern in self.patterns.STATUS_HUKUMAN_PATTERNS:\n",
    "            matches = re.findall(pattern, search_area)\n",
    "            for match in matches:\n",
    "                status_text = match[0].strip() if isinstance(match, tuple) else match.strip()\n",
    "                status_text = re.sub(r'\\s+', ' ', status_text).strip()\n",
    "                \n",
    "                if 30 <= len(status_text) <= 500:\n",
    "                    return status_text\n",
    "            \n",
    "        return \"\"\n",
    "\n",
    "    def extract_ringkasan_fakta(self, text: str, min_len: int = 200, max_len: int = 1500) -> str:\n",
    "        \"\"\"\n",
    "        Ekstrak ringkasan fakta dari dokumen, membersihkan header/footer,\n",
    "        dan memastikan panjang yang wajar.\n",
    "        \"\"\"\n",
    "        # Bersihkan teks dasar\n",
    "        text = self.clean_text(text)\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # Pola untuk menandai awal dan akhir potensial dari ringkasan fakta\n",
    "        start_keywords = [\n",
    "            re.compile(r'DUDUK\\s+PERKARA', re.IGNORECASE),\n",
    "            re.compile(r'I\\.\\s*PERKARA', re.IGNORECASE),\n",
    "            re.compile(r'FAKTA-FAKTA', re.IGNORECASE),\n",
    "            re.compile(r'MENIMBANG(?:\\s+BAHWA|\\,\\s+bahwa)?\\s+permohonan', re.IGNORECASE),\n",
    "            re.compile(r'DALAM\\s+POKOK\\s+PERKARA', re.IGNORECASE),\n",
    "            re.compile(r'TENTANG\\s+PERKARA', re.IGNORECASE),\n",
    "            re.compile(r'POKOK\\s+GUGATAN', re.IGNORECASE), # Untuk perdata/TUN\n",
    "            re.compile(r'URAIAN\\s+PERBUATAN', re.IGNORECASE), # Untuk pidana\n",
    "        ]\n",
    "        \n",
    "        end_keywords = [\n",
    "            re.compile(r'TENTANG\\s+HUKUM', re.IGNORECASE),\n",
    "            re.compile(r'MENIMBANG(?:\\s+TENTANG|\\,\\s+tentang)?\\s+HUKUM', re.IGNORECASE),\n",
    "            re.compile(r'DALAM\\s+PERTIMBANGAN\\s+HUKUM', re.IGNORECASE),\n",
    "            re.compile(r'MEMUTUSKAN', re.IGNORECASE),\n",
    "            re.compile(r'MENGADILI', re.IGNORECASE),\n",
    "            re.compile(r'AMAR\\s+PUTUSAN', re.IGNORECASE),\n",
    "            re.compile(r'DALAM\\s+EKSEPSI', re.IGNORECASE), # Jika ada eksepsi setelah fakta\n",
    "            re.compile(r'Demikian\\s+diputus\\s+dalam\\s+rapat\\s+musyawarah', re.IGNORECASE),\n",
    "        ]\n",
    "\n",
    "        fact_start_pos = -1\n",
    "        fact_end_pos = -1\n",
    "\n",
    "        # Cari awal bagian fakta\n",
    "        for pattern in start_keywords:\n",
    "            match = pattern.search(text)\n",
    "            if match:\n",
    "                fact_start_pos = match.end()\n",
    "                break\n",
    "\n",
    "        # Cari akhir bagian fakta (mulai pencarian dari fact_start_pos jika ditemukan)\n",
    "        search_from = fact_start_pos if fact_start_pos != -1 else 0\n",
    "        for pattern in end_keywords:\n",
    "            match = pattern.search(text, search_from)\n",
    "            if match:\n",
    "                fact_end_pos = match.start()\n",
    "                break\n",
    "\n",
    "        extracted_content = \"\"\n",
    "        if fact_start_pos != -1 and fact_end_pos != -1 and fact_end_pos > fact_start_pos:\n",
    "            extracted_content = text[fact_start_pos:fact_end_pos].strip()\n",
    "            self.logger.debug(f\"Fact section found between {fact_start_pos} and {fact_end_pos}\")\n",
    "        elif fact_start_pos != -1: # Jika hanya awal ditemukan, ambil dari awal hingga akhir dokumen\n",
    "            extracted_content = text[fact_start_pos:].strip()\n",
    "            self.logger.debug(f\"Fact section from {fact_start_pos} to end (no end marker).\")\n",
    "        elif fact_end_pos != -1: # Jika hanya akhir ditemukan, ambil dari awal dokumen hingga posisi akhir\n",
    "            extracted_content = text[:fact_end_pos].strip()\n",
    "            self.logger.debug(f\"Fact section from beginning to {fact_end_pos} (no start marker).\")\n",
    "        else: # Fallback: tidak ada penanda jelas, coba ekstrak dari blok teks substansial\n",
    "            self.logger.debug(\"No clear fact markers found. Using heuristic fallback.\")\n",
    "            # Hapus header umum yang sangat mungkin ada di awal dokumen\n",
    "            text_after_header_clean = re.sub(\n",
    "                r'^(?:PUTUSAN\\s+NOMOR\\s+[\\s\\S]*?DENGAN\\s+RAHMAT\\s+TUHAN\\s+YANG\\s+MAHA\\s+ESA|PENGADILAN\\s+NEGERI.*?\\n+)*',\n",
    "                '', text, flags=re.IGNORECASE | re.DOTALL\n",
    "            ).strip()\n",
    "\n",
    "            # Ambil beberapa paragraf pertama yang substansial\n",
    "            lines = text_after_header_clean.split('\\n')\n",
    "            \n",
    "            # Filter baris yang sangat pendek atau hanya berisi penomoran/artefak\n",
    "            content_candidate_lines = []\n",
    "            for line in lines:\n",
    "                stripped_line = line.strip()\n",
    "                # Hindari baris yang terlalu pendek, nomor halaman, atau baris yang terlalu berulang\n",
    "                if len(stripped_line) > 50 and not re.fullmatch(r'^\\s*[-_]?\\s*\\d+\\s*[-_]?\\s*$', stripped_line) and \\\n",
    "                   not re.fullmatch(r'^\\s*[A-Z\\s]+\\s*$', stripped_line) and \\\n",
    "                   not re.fullmatch(r'^[\\s\\W_]*$', stripped_line): # Bukan hanya simbol\n",
    "                    content_candidate_lines.append(stripped_line)\n",
    "                elif len(stripped_line) > 10 and re.search(r'[a-zA-Z0-9]', stripped_line): # Keep reasonably long lines with words\n",
    "                    content_candidate_lines.append(stripped_line)\n",
    "\n",
    "            extracted_content = \"\\n\".join(content_candidate_lines).strip()\n",
    "            self.logger.debug(f\"Fallback extracted content length: {len(extracted_content)}\")\n",
    "\n",
    "        # --- Pembersihan akhir dan pemotongan panjang ---\n",
    "        extracted_content = self.clean_text(extracted_content) # Bersihkan lagi setelah segmentasi\n",
    "        \n",
    "        # Hapus sisa-sisa pola umum yang tidak diinginkan, tapi dengan hati-hati\n",
    "        general_cleanup_patterns = [\n",
    "            re.compile(r'Disclaimer\\s*[:\\-].*$', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'Halaman\\s+\\d+\\s+dari\\s+\\d+.*$', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'MAHKAMAH\\s+AGUNG.*$', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'Kepaniteraan.*@mahkamahagung\\.go\\.id.*$', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'Catatan\\s*:\\s*Putusan\\s*ini.*$', re.IGNORECASE | re.DOTALL),\n",
    "            re.compile(r'\\bSALINAN\\b[\\s\\S]*?\\bPANITERA\\b', re.IGNORECASE | re.DOTALL),\n",
    "        ]\n",
    "        for pattern in general_cleanup_patterns:\n",
    "            extracted_content = re.sub(pattern, '', extracted_content) # Apply already compiled patterns\n",
    "        extracted_content = self.clean_text(extracted_content) # Bersihkan final\n",
    "\n",
    "        # Potong sesuai panjang maksimal\n",
    "        if len(extracted_content) > max_len:\n",
    "            extracted_content = extracted_content[:max_len]\n",
    "            last_period = extracted_content.rfind('.')\n",
    "            if last_period > min_len: # Pastikan tidak memotong terlalu awal dari min_len\n",
    "                extracted_content = extracted_content[:last_period + 1]\n",
    "            else: # Jika tidak ada titik yang baik, potong di kata terakhir\n",
    "                extracted_content = extracted_content.rsplit(' ', 1)[0] + \"...\"\n",
    "        \n",
    "        # Pastikan panjang minimum terpenuhi, jika tidak, coba lebih agresif dari teks asli\n",
    "        if len(extracted_content) < min_len and len(text) >= min_len:\n",
    "            self.logger.warning(f\"Extracted facts too short ({len(extracted_content)} chars). Original text had {len(text)} chars. Attempting aggressive fallback.\")\n",
    "            # Ambil bagian awal teks setelah header yang sangat umum (lebih berani)\n",
    "            aggressive_fallback_text = re.sub(\n",
    "                r'^(.*?PUTUSAN\\s+NOMOR\\s+[\\s\\S]*?(?:DENGAN\\s+RAHMAT\\s+TUHAN\\s+YANG\\s+MAHA\\s+ESA|MAJELIS\\s+HAKIM|MENIMBANG|MENGADILI)\\s*?\\n+)?',\n",
    "                '', text, flags=re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            aggressive_fallback_text = self.clean_text(aggressive_fallback_text)\n",
    "            if len(aggressive_fallback_text) > min_len:\n",
    "                return aggressive_fallback_text[:min_len].strip() + \"...\"\n",
    "            else:\n",
    "                return aggressive_fallback_text.strip() # Kembalikan apa pun yang tersisa\n",
    "\n",
    "        return extracted_content.strip()\n",
    "\n",
    "    def extract_metadata(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Ekstrak semua metadata dari teks (Tidak Berubah).\"\"\"\n",
    "        if not text:\n",
    "            self.logger.warning(\"Input text is empty, returning empty metadata.\")\n",
    "            return {}\n",
    "        \n",
    "        text = self.clean_text(text)\n",
    "        \n",
    "        metadata = {\n",
    "            \"no_perkara\": self.extract_nomor_perkara(text),\n",
    "            \"tanggal\": self.extract_tanggal(text),\n",
    "            \"jenis_perkara\": self.extract_jenis_perkara(text),\n",
    "            \"pasal\": \"; \".join(self.extract_pasal(text)),\n",
    "            \"nama\": self.extract_personal_data(text, 'nama'),\n",
    "            \"umur\": self.extract_personal_data(text, 'umur'),\n",
    "            \"jenis_kelamin\": self.extract_personal_data(text, 'jenis_kelamin'),\n",
    "            \"pekerjaan\": self.extract_personal_data(text, 'pekerjaan'),\n",
    "            \"alamat\": self.extract_personal_data(text, 'alamat'),\n",
    "            \"status_hukuman\": self.extract_status_hukuman(text),\n",
    "            \"ringkasan_fakta\": self.extract_ringkasan_fakta(text)\n",
    "        }\n",
    "        \n",
    "        found_fields = [k for k, v in metadata.items() if v and v.strip() and v not in [\"N/A\", \"UNKNOWN\"]]\n",
    "        self.logger.debug(f\"Extracted fields: {found_fields}\")\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "def process_all_cases():\n",
    "    \"\"\"Proses semua file txt dalam folder raw dan simpan sebagai JSON (Tidak Berubah).\"\"\"\n",
    "    setup_logging()\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    txt_files = list(RAW_DIR.glob(\"*.txt\"))\n",
    "    if not txt_files:\n",
    "        logger.warning(f\"No .txt files found in {RAW_DIR}. Please ensure raw text files are in this directory.\")\n",
    "        print(f\"❌ Tidak ada file .txt ditemukan di {RAW_DIR}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"Found {len(txt_files)} .txt files to process.\")\n",
    "    print(f\"🔍 Ditemukan {len(txt_files)} file untuk diproses.\")\n",
    "    \n",
    "    extractor = ImprovedSmartExtractor()\n",
    "    results = []\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for file_path in txt_files:\n",
    "        current_case_id = file_path.stem\n",
    "        try:\n",
    "            logger.info(f\"Processing {file_path.name}\")\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            if not text.strip():\n",
    "                logger.warning(f\"File {file_path.name} is empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            metadata = extractor.extract_metadata(text)\n",
    "            \n",
    "            if metadata.get(\"no_perkara\") and len(metadata[\"no_perkara\"]) > 10:\n",
    "                current_case_id = metadata[\"no_perkara\"].replace(\"/\", \"_\").replace(\".\", \"_\").strip()\n",
    "            \n",
    "            metadata.update({\n",
    "                \"case_id\": current_case_id,\n",
    "                \"file_name\": file_path.name,\n",
    "                \"file_size\": len(text),\n",
    "                \"processed_at\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            results.append(metadata)\n",
    "            success_count += 1\n",
    "            \n",
    "            found_count = sum(1 for k, v in metadata.items() if k not in ['case_id', 'file_name', 'file_size', 'processed_at'] and v and v.strip() and v not in [\"N/A\", \"UNKNOWN\"])\n",
    "            print(f\"✅ {file_path.name} (ID: {current_case_id}) - {found_count} field terisi.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            logger.error(f\"Failed to process {file_path.name} (ID: {current_case_id}): {e}\", exc_info=True)\n",
    "            print(f\"❌ Error processing {file_path.name} (ID: {current_case_id}): {e}\")\n",
    "    \n",
    "    if results:\n",
    "        unique_case_ids = set()\n",
    "        cleaned_results = []\n",
    "        for res in results:\n",
    "            if res['case_id'] in unique_case_ids:\n",
    "                logger.warning(f\"Duplicate case_id '{res['case_id']}' found for file '{res['file_name']}'. Skipping this duplicate entry.\")\n",
    "            else:\n",
    "                unique_case_ids.add(res['case_id'])\n",
    "                cleaned_results.append(res)\n",
    "        \n",
    "        if len(cleaned_results) < len(results):\n",
    "            logger.warning(f\"Removed {len(results) - len(cleaned_results)} duplicate case entries.\")\n",
    "            results = cleaned_results\n",
    "\n",
    "        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"Successfully saved {len(results)} unique cases to {OUTPUT_FILE}.\")\n",
    "        print(f\"💾 Berhasil menyimpan {len(results)} kasus unik ke {OUTPUT_FILE}.\")\n",
    "        \n",
    "        print(f\"\\n📊 STATISTIK EKSTRAKSI KESELURUHAN:\")\n",
    "        print(f\"Total file .txt ditemukan: {len(txt_files)}\")\n",
    "        print(f\"Berhasil diproses (unik): {success_count - (len(cleaned_results) - len(results))}\")\n",
    "        print(f\"Error saat proses file: {error_count}\")\n",
    "        print(f\"Total kasus disimpan di '{OUTPUT_FILE}': {len(results)}\")\n",
    "        \n",
    "        field_stats = {}\n",
    "        expected_fields = [\n",
    "            \"no_perkara\", \"tanggal\", \"jenis_perkara\", \"pasal\", \"nama\", \n",
    "            \"umur\", \"jenis_kelamin\", \"pekerjaan\", \"alamat\", \"status_hukuman\", \"ringkasan_fakta\"\n",
    "        ]\n",
    "        for field in expected_fields:\n",
    "            field_stats[field] = 0\n",
    "\n",
    "        for result in results:\n",
    "            for field in expected_fields:\n",
    "                if field in result and result[field] and result[field].strip() and result[field] not in [\"N/A\", \"UNKNOWN\"]:\n",
    "                    field_stats[field] += 1\n",
    "        \n",
    "        print(f\"\\n📈 REKAP EKSTRAKSI PER FIELD (dari {len(results)} kasus):\")\n",
    "        for field, count in sorted(field_stats.items()):\n",
    "            percentage = (count / len(results)) * 100\n",
    "            print(f\"- {field.replace('_', ' ').title()}: {count}/{len(results)} ({percentage:.1f}%)\")\n",
    "    \n",
    "    else:\n",
    "        logger.warning(\"No cases were successfully processed or saved.\")\n",
    "        print(\"❌ Tidak ada kasus yang berhasil diproses atau disimpan.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_cases()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
